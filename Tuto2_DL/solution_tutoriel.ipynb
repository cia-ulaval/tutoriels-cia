{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xqHkpjW7sYzm"
   },
   "source": [
    "# Réseaux de neurones\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GioCTnHoC-OT"
   },
   "source": [
    "Dans ce tutoriel, nous allons explorer les réseaux de neurones. Le but est d'expliquer, dans les grandes lignes, le fonctionnement d'un réseau de neurones. La première partie du tutoriel est écrite avec PyTorch+Lightning, tandis que la section 2, qui contient un exercice, est écrite en PyTorch pure. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2Lc7sxGMsfAg"
   },
   "source": [
    "**Quelques avertissements avant de commencer** \n",
    "\n",
    "1. Il y a beaucoup de code dans ce notebook qui ne sert qu'à faire de beaux graphiques. Veuillez simplement l'ignorer puisque, contrairement à Colab, je ne peux pas masquer le code dans les cellules.\n",
    "\n",
    "2. L'importation des librairies est relativement lent, donc exécutez tout de suite cette cellule. J'ai caché les sorties, si jamais vous avez un problème, enlevez `%%capture` puis regardez le message d'erreur.\n",
    "\n",
    "3. Je ne garantis pas non plus que l'architecture du réseau de neurones ainsi que les hyperparamètres sont optimaux. Avec 10 époques, j'obtiens généralement environ 90%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!uv pip install -r requirements.txt\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torchaudio\n",
    "import lightning as L\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Audio\n",
    "import numpy as np\n",
    "import deeplake\n",
    "import random\n",
    "import seaborn as sn\n",
    "import os\n",
    "from utils import AudioNet, ClassificationModel, AudioDataset, collate_fn, compute_accuracy_and_conf_mat\n",
    "import tqdm\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3NgckhGVFF1s"
   },
   "source": [
    "# Créer le jeu de données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yFcOsK-vHiSs"
   },
   "source": [
    "Dans le cadre de ce tutoriel, nous allons entraîner un réseau de neurones convolutif (CNN) sur le jeu de données Free Spoken Digit Dataset (FSDD), qui est l'équivalent de MNIST mais avec de l'audio.\n",
    "\n",
    "Commençons par importer le jeu de données. On sépare les données en trois sections : entraînement, validation et test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "editable": true,
    "id": "dPLMl1TMdBhd",
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "L.pytorch.seed_everything(42, workers=True)\n",
    "\n",
    "ds = deeplake.load(\"hub://activeloop/spoken_mnist\")\n",
    "\n",
    "N_train = 2000\n",
    "N_val = 500\n",
    "\n",
    "# shuffle the dataset\n",
    "lst_shfl = list(range(len(ds)))\n",
    "random.shuffle(lst_shfl)\n",
    "ds = ds[lst_shfl]\n",
    "\n",
    "# split the dataset\n",
    "ds_train = ds[:N_train]\n",
    "ds_val = ds[N_train:N_train+N_val]\n",
    "ds_test = ds[N_train+N_val:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vous pouvez visualiser les données. Les données ont été enregistrées par 6 personnes, qui ont chacun répétés 50 fois chaque chiffre de 0 à 9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jar9NawMJSaQ"
   },
   "source": [
    "Nous allons maintenant définir nos dataloaders. Les dataloaders font plusieurs choses en même temps. Premièrement, ils vont prendre les données et vont créer des batchs, qui seront fournies au réseau de neurone à entraîner. De plus, durant l'entraînement, les données seront permutées pour éviter d'avoir des batchs identiques à chaque étape.\n",
    "\n",
    "Vous pouvez vous amuser à modifier la batch_size et le nombre d'époques d'entraînement. Une batch size plus grande vient généralement avec une meilleure utilisation du GPU, mais une batch size trop grande peut donner des résultats moins bons. Plus d'époques veut dire que le modèle va probablement être mieux entraînés et va donner de meilleures performances, mais l'entraînement durera beaucoup plus longtemps.\n",
    "\n",
    "Les hyperparamètres donnés permettent d'obtenir environ 90% sur le jeu de données d'entraînement, mais vous pouvez jouer avec pour mieux comprendre leurs effets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "anmeFrl1_ZPc"
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "max_epochs = 10\n",
    "num_workers = 4 # Vous pouvez en mettre plus ou moins selon la puissance de votre ordinateur\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(AudioDataset(ds_train),\n",
    "                            batch_size=batch_size,\n",
    "                            shuffle=True,\n",
    "                            collate_fn=collate_fn,\n",
    "                            num_workers=num_workers)\n",
    "\n",
    "validation_loader = torch.utils.data.DataLoader(AudioDataset(ds_val),\n",
    "                            batch_size=batch_size,\n",
    "                            shuffle=False,\n",
    "                            collate_fn=collate_fn,\n",
    "                            num_workers=num_workers)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(AudioDataset(ds_test),\n",
    "                            batch_size=batch_size,\n",
    "                            shuffle=False,\n",
    "                            collate_fn=collate_fn,\n",
    "                            num_workers=num_workers)\n",
    "\n",
    "# Ce dataloader n'est pas toujours nécessaire, mais je l'ai rajouté ignorer un warning.\n",
    "testing_train_loader = torch.utils.data.DataLoader(AudioDataset(ds_train),\n",
    "                            batch_size=batch_size,\n",
    "                            shuffle=False,\n",
    "                            collate_fn=collate_fn,\n",
    "                            num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YAqxTQoUsmXI"
   },
   "source": [
    "# Entraînement d'un réseau de neurones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OKaPDDA2VFQV"
   },
   "source": [
    "Dans cette section, nous allons entraîner un réseau de neurones avec PyTorch + Lightning.\n",
    "\n",
    "PyTorch est une librairie qui définit toutes les fonctions nécessaires pour entraîner un réseau de neurones. On va donc pouvoir définir le réseau de neurones et l'entraîner.\n",
    "\n",
    "Lightning a été introduit pour éviter aux utilisateurs de réécrire à chaque fois le même \"boiler plate code\". C'est du code qui doit être défini à chaque fois et qui est toujours pareil. Utiliser Lightning permet ainsi de sauver beaucoup de temps passé à réécrire toutes les fonctions nécessaires à entraîner un réseau de neurones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OwC0YhnyW3x1"
   },
   "source": [
    "Instancions notre réseau de neurones et regardons ce qui se trouve à l'intérieur. On va s'intéresser aux quatres modules les plus importants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "htYGrQ2UzPUV"
   },
   "outputs": [],
   "source": [
    "first_model = AudioNet(n_classes=10, dropout_probability=0.2)\n",
    "first_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-17T14:59:56.516189Z",
     "iopub.status.busy": "2025-08-17T14:59:56.516114Z",
     "iopub.status.idle": "2025-08-17T14:59:56.519738Z",
     "shell.execute_reply": "2025-08-17T14:59:56.519247Z",
     "shell.execute_reply.started": "2025-08-17T14:59:56.516180Z"
    }
   },
   "source": [
    "**Linear**\n",
    "\n",
    "La couche linéaire est la première couche du réseau de neurones à avoir été utilisée, bien avant l'apparition des couches de convolutions. Simplement, la couche linéaire est une matrice qui est multipliée au vecteur d'entrée. \n",
    "\n",
    "Ainsi, pour une entrée $X \\in \\mathbb{R}^{d_{\\mathrm{in}}}$, la couche linéaire est une matrice $W \\in \\mathbb{R}^{d_{\\mathrm{out}} \\times d_{\\mathrm{in}}}$ telle que\n",
    "$$ Y = WX \\in \\mathbb{R}^{d_{\\mathrm{out}}}$$\n",
    "est la sortie de la couche linéaire."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i7EIzNxOYTRN"
   },
   "source": [
    "**Conv1d**\n",
    "\n",
    "Dans une couche de convolution, on applique un filtre (qui contient des paramètres entraînables) sur un signal. Dans un signal, chaque prise de mesure est corrélée aux données prises juste avant et juste après. De plus, il n'est généralement que peu informatif d'utiliser un seul point de données dans un signal. La convolution va donc incorporer cette information temporelle pour obtenir une nouvelle représentation plus informative.\n",
    "\n",
    "Dans l'image suivante, on a un filtre qui contient $[1,0,1]$. Appliqué sur le vecteur $[1,0,0]$, on a :\n",
    "\n",
    "$$ 1 \\times 1 + 0 \\times 0 + 0 \\times 1 = 1$$\n",
    "\n",
    "Plus la taille du noyau est grande (paramètre kernel_size de Conv1d), plus on va agréger le contexte autour d'un seul point. Si le noyau est trop grand, l'entièreté du signal est considéré et la convolution donne une représentation non-informative. Si le noyau est trop petit, il va seulement utiliser un point, ce qui n'est pas informatif non plus.\n",
    "\n",
    "De plus, on va généralement faire cette opération pour un grand nombre de filtres. Dans la première couche d'AudioNet, on applique 32 filtres sur le signal d'entrée.\n",
    "\n",
    "<img src=\"./images/conv1d.png\" width=\"50%\" class=\"center\"/>\n",
    "\n",
    "[source](https://stackoverflow.com/questions/65006011/size-of-output-of-a-conv1d-layer-in-keras)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pxPTexcAbBnE"
   },
   "source": [
    "**ReLU**\n",
    "\n",
    "La grande force des réseaux de neurones est l'application de non-linéarités entre les différentes couches. En effet, si on multipliait toutes les matrices d'un réseau de neurone sans ajouter de la non-linéarité, le réseau de neurones est équivalent à une régression linéaire.\n",
    "\n",
    "Selon moi, la fonction d'activation la plus connue et la plus utilisée est la ReLU (*rectified linear unit*) :\n",
    "$$ReLU(x) = \\max(0, x).$$\n",
    "\n",
    "\n",
    "<img src=\"./images/relu.png\" width=\"50%\" class=\"center\"/>\n",
    "\n",
    "[source](https://machinelearningmastery.com/rectified-linear-activation-function-for-deep-learning-neural-networks/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IFyCa-n-bDTg"
   },
   "source": [
    "**Dropout**\n",
    "\n",
    "Le dropout est une méthode de régularisation qui va supprimer des neurones durant l'entraînement de manière aléatoire. À chaque époque, les neurones supprimés vont être différents.\n",
    "\n",
    "Entraîner un modèle avec du dropout force le modèle à utiliser tous les neurones correctement. Si le modèle est capable de s'entraîner même en perdant des neurones à chaque itération, il devrait bien fonctionner après l'entraînement.\n",
    "\n",
    "<img src=\"./images/dropout.png\" width=\"50%\" class=\"center\"/>\n",
    "\n",
    "[source](https://jmlr.org/papers/v15/srivastava14a.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1Q5Ou4pTbyQU"
   },
   "source": [
    "Je vous fournir de plus la documentation PyTorch des différents layers utilisés :\n",
    "\n",
    "[Conv1d](https://pytorch.org/docs/stable/generated/torch.nn.Conv1d.html)\n",
    "\n",
    "[ReLU](https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html)\n",
    "\n",
    "[Dropout](https://pytorch.org/docs/stable/generated/torch.nn.Dropout.html)\n",
    "\n",
    "[BatchNorm1d](https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm1d.html)\n",
    "\n",
    "[MaxPool1d](https://pytorch.org/docs/stable/generated/torch.nn.MaxPool1d.html)\n",
    "\n",
    "[Linear](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e7E5qrPCjEnV"
   },
   "source": [
    "L'entraînement de modèle se fait en deux phases:\n",
    "\n",
    "1.   Forward propagation\n",
    "2.   Backward propagation\n",
    "\n",
    "\n",
    "**Forward propagation**\n",
    "\n",
    "La \"forward propagation\" est l'étape d'inférence du modèle. Le modèle prend un signal en entrée, puis multiplie le signal avec la première couche. Ensuite, une fonction d'activation est appliquée. On continue jusqu'à la dernière couche.\n",
    "\n",
    "Pour un réseau de neurones linéaire (MLP) à trois couches, on a :\n",
    "\n",
    "$$ MLP(x) = W_3\\sigma(W_2\\sigma(W_1 x + b_1) + b_2) + b_3$$\n",
    "\n",
    "avec $W_1, W_2, W_3$ les poids des couches linéaires, $b_1, b_2, b_3$ le biais des couches et $\\sigma$ une fonction d'activation.\n",
    "\n",
    "On applique parfois un [SoftMax](https://pytorch.org/docs/stable/generated/torch.nn.Softmax.html) à la dernière couche pour obtenir la probabilité d'appartenance à différentes classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour le plaisir, je vous fais un petit exemple qui illustre ce qui se passe à la sortie de chaque couche du modèle AudioNet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "jRjaTbJweMfp",
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide_input"
    ]
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 4, figsize=(20,10))\n",
    "\n",
    "first_model.eval()\n",
    "index = 0\n",
    "axs[0,0].plot(ds_train[index]['audio'])\n",
    "axs[0,0].set_title(\"Entrée du modèle\")\n",
    "\n",
    "with torch.no_grad():\n",
    "  out_cnn = first_model.cnn_layers[0](torch.tensor(ds_train[index][\"audio\"].data()['value']).transpose(1,0).float().unsqueeze(0))\n",
    "axs[0,1].plot(out_cnn.mean(1).reshape(-1,))\n",
    "axs[0,1].set_title(\"Moyenne (sur les filtres) du signal\\n après 1 couche de convolution\")\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "  out_cnn = first_model.cnn_layers[0:5](torch.tensor(ds_train[index][\"audio\"].data()['value']).transpose(1,0).float().unsqueeze(0))\n",
    "axs[0,2].plot(out_cnn.mean(1).reshape(-1,))\n",
    "axs[0,2].set_title(\"Moyenne (sur les filtres) du signal\\n après 2 couche de convolution\")\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "  out_cnn = first_model.cnn_layers[0:9](torch.tensor(ds_train[index][\"audio\"].data()['value']).transpose(1,0).float().unsqueeze(0))\n",
    "axs[0,3].plot(out_cnn.mean(1).reshape(-1,))\n",
    "axs[0,3].set_title(\"Moyenne (sur les filtres) du signal\\n après 3 couche de convolution\")\n",
    "\n",
    "with torch.no_grad():\n",
    "  out_cnn = first_model.cnn_layers(torch.tensor(ds_train[index][\"audio\"].data()['value']).transpose(1,0).float().unsqueeze(0))\n",
    "axs[1,0].plot(out_cnn.mean(-1).reshape(-1,))\n",
    "axs[1,0].set_title(\"Moyenne (sur le temps) du signal\\n après le maxpooling\")\n",
    "\n",
    "with torch.no_grad():\n",
    "  out = first_model.linear_layers[0](out_cnn.mean(-1))\n",
    "axs[1,1].plot(out.reshape(-1,))\n",
    "axs[1,1].set_title(\"Sortie après une \\ncouche linéaire\")\n",
    "\n",
    "with torch.no_grad():\n",
    "  out = nn.Softmax(dim=1)(first_model(torch.tensor(ds_train[index][\"audio\"].data()['value']).transpose(1,0).float().unsqueeze(0)))\n",
    "axs[1,2].scatter(np.arange(10), out.reshape(-1,))\n",
    "axs[1,2].set_ylim(-0.05,1)\n",
    "axs[1,2].set_title(\"Classification du modèle\")\n",
    "\n",
    "fig.delaxes(axs[1,3])\n",
    "\n",
    "print(f\"La donnée à classifier est un {ds_train[index]['labels'].data()['value'].item()}. La sortie du réseau de neurones est un {out.argmax(-1).item()}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vNQbb3sliok_"
   },
   "source": [
    "**Backward propagation**\n",
    "\n",
    "L'étape de la *backprop* est automatiquement gérée par PyTorch, mais il est important de comprendre comment cela fonctionne, pour pouvoir mieux comprendre comment les réseaux de neurones s'entraînent.\n",
    "\n",
    "Pour ce faire, on calcule la dérivée de la perte en fonction de la valeur prédite par chaque neurone de sortie du modèle. Ensuite, on va propager le gradient de la dernière couche à la première couche, mettant ainsi à jour chaque neurone.\n",
    "\n",
    "On fait donc de la descente de gradient stochastique (SGD) sur chaque poids du modèle, le mettant à jour jusqu'à ce que le modèle ne fasse plus d'erreur ou qu'on soit satisfait du taux d'erreur.\n",
    "\n",
    "\n",
    "Pour en apprendre davantage sur la backprop, je recommande **fortement** la playliste de 3Blue1Brown : https://youtu.be/aircAruvnKk?si=m4XFzh893N6REXiZ\n",
    "\n",
    "<img src=\"./images/backprop.png\" width=\"50%\" class=\"center\"/>\n",
    "\n",
    "[Source](https://devforum.roblox.com/t/understanding-neural-network-backpropagation-learning-algorithm/1838115)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UQUD7i--lnVD"
   },
   "source": [
    "Entraînons maintenant le modèle. Pour ce faire, on initialise le réseau de neurones, la classe d'entraînement et l'entraîneur. La classe `Trainer` va automatiquement gérer l'optimisation de notre modèle.\n",
    "\n",
    "Vous pouvez jouer avec le dropout, l'optimiseur et le learning rate, pour voir la différence que cela fait durant l'entraînement. La classe `ClassificationModel` supporte `SGD`et `Adam` comme optimiseur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n-_RDjWhv22k",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Initialiser le réseau de neurones\n",
    "model = AudioNet(dropout_probability=0.2)\n",
    "\n",
    "# Intialiser le modèle à entraîner\n",
    "lightning_model = ClassificationModel(model, optimizer=\"Adam\", lr=0.005)\n",
    "\n",
    "# Initialiser l'entraîneur\n",
    "trainer = L.Trainer(accelerator='auto',max_epochs=max_epochs,\n",
    "                    log_every_n_steps=10, logger=False, enable_checkpointing=False,\n",
    "                    deterministic=True)\n",
    "\n",
    "# Entraîner le modèle\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\") \n",
    "    trainer.fit(model=lightning_model, train_dataloaders=train_loader, val_dataloaders=validation_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2AXALDG-mBpE"
   },
   "source": [
    "On calcule maintenant l'accuracy sur les données d'entraînement, de validation et de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GwmOSaVdBwPV"
   },
   "outputs": [],
   "source": [
    "print(\"Calcul de l'erreur sur le jeu de données d'entraînement\")\n",
    "trainer.validate(model=lightning_model, dataloaders=testing_train_loader)\n",
    "\n",
    "print(\"Calcul de l'erreur sur le jeu de données de validation\")\n",
    "trainer.validate(model=lightning_model, dataloaders=validation_loader)\n",
    "\n",
    "print(\"Calcul de l'erreur sur le jeu de données de test\")\n",
    "trainer.test(model=lightning_model, dataloaders=test_loader)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qaBuExQnmpty"
   },
   "source": [
    "Finalement, on peut calculer les matrices de confusions sur les trois ensembles de données. La matrice de confusion nous permet de savoir si les données sont bien classifiées ou non, et comment elles sont classifiées quand elles ne sont pas classifiées correctement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "YHZ1GhU89I9N"
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(20,5))\n",
    "\n",
    "trainer.predict(model=lightning_model, dataloaders=testing_train_loader, return_predictions=False)\n",
    "sn.heatmap(lightning_model.conf_mat.to(int), annot=True, fmt=\"d\", ax=axs[0])\n",
    "axs[0].set_title(\"Matrice de confusion du jeu de donnés d'entraînement\")\n",
    "\n",
    "trainer.predict(model=lightning_model, dataloaders=validation_loader, return_predictions=False)\n",
    "sn.heatmap(lightning_model.conf_mat.to(int), annot=True, fmt=\"d\", ax=axs[1])\n",
    "axs[1].set_title(\"Matrice de confusion du jeu de donnés de validation\")\n",
    "\n",
    "trainer.predict(model=lightning_model, dataloaders=test_loader, return_predictions=False)\n",
    "sn.heatmap(lightning_model.conf_mat.to(int), annot=True, fmt=\"d\", ax=axs[2])\n",
    "axs[2].set_title(\"Matrice de confusion du jeu de donnés de test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6D73gSenm2a-"
   },
   "source": [
    "On reprend maintenant notre exemple de propagation dans le modèle. On ne peut pas vraiment déduire quoique ce soit de ces graphiques, puisque c'est la moyenne sur beaucoup de filtres, mais c'est tout de même intéressant à regarder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "W-cbD1RE8baL"
   },
   "outputs": [],
   "source": [
    "# Exemple de propagation de donnée d'un modèle entraîné\n",
    "fig, axs = plt.subplots(2, 4, figsize=(20,10))\n",
    "\n",
    "model.eval()\n",
    "index = 0\n",
    "axs[0,0].plot(ds_train[index]['audio'])\n",
    "axs[0,0].set_title(\"Entrée du modèle\")\n",
    "\n",
    "with torch.no_grad():\n",
    "  out_cnn = model.cnn_layers[0](torch.tensor(ds_train[index][\"audio\"].data()['value']).transpose(1,0).float().unsqueeze(0))\n",
    "axs[0,1].plot(out_cnn.mean(1).reshape(-1,))\n",
    "axs[0,1].set_title(\"Moyenne (sur les filtres) du signal\\n après 1 couche de convolution\")\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "  out_cnn = model.cnn_layers[0:5](torch.tensor(ds_train[index][\"audio\"].data()['value']).transpose(1,0).float().unsqueeze(0))\n",
    "axs[0,2].plot(out_cnn.mean(1).reshape(-1,))\n",
    "axs[0,2].set_title(\"Moyenne (sur les filtres) du signal\\n après 2 couche de convolution\")\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "  out_cnn = model.cnn_layers[0:9](torch.tensor(ds_train[index][\"audio\"].data()['value']).transpose(1,0).float().unsqueeze(0))\n",
    "axs[0,3].plot(out_cnn.mean(1).reshape(-1,))\n",
    "axs[0,3].set_title(\"Moyenne (sur les filtres) du signal\\n après 3 couche de convolution\")\n",
    "\n",
    "with torch.no_grad():\n",
    "  out_cnn = model.cnn_layers(torch.tensor(ds_train[index][\"audio\"].data()['value']).transpose(1,0).float().unsqueeze(0))\n",
    "axs[1,0].plot(out_cnn.mean(-1).reshape(-1,))\n",
    "axs[1,0].set_title(\"Moyenne (sur le temps) du signal\\n après le maxpooling\")\n",
    "\n",
    "with torch.no_grad():\n",
    "  out = model.linear_layers[0](out_cnn.mean(-1))\n",
    "axs[1,1].plot(out.reshape(-1,))\n",
    "axs[1,1].set_title(\"Sortie après une \\ncouche linéaire\")\n",
    "\n",
    "with torch.no_grad():\n",
    "  out = nn.Softmax(dim=1)(model(torch.tensor(ds_train[index][\"audio\"].data()['value']).transpose(1,0).float().unsqueeze(0)))\n",
    "axs[1,2].scatter(np.arange(10), out.reshape(-1,))\n",
    "axs[1,2].set_title(\"Classification du modèle\")\n",
    "axs[1,2].set_ylim(-0.05,1)\n",
    "\n",
    "fig.delaxes(axs[1,3])\n",
    "\n",
    "print(f\"La donnée à classifier est un {ds_train[index]['labels'].data()['value'].item()}. La sortie du réseau de neurones est un {out.argmax(-1).item()}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uZHrkp_ispKS"
   },
   "source": [
    "# Exercice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U428qmNWnZut"
   },
   "source": [
    "Le but de cet exercice est de vous montrer comment entraîner un réseau de neurones sans utiliser Lightning. On utilise ainsi du pur PyTorch pour faire notre entraînement.\n",
    "\n",
    "J'ai fourni un document avec la solution. Essayez de faire l'exercice sans regarder la solution. Aussi, c'est évident que ChatGPT (ou tout autre LLM) connaît les réponses, parce que c'est du code \"boiler plate\" super simple. C'est plus intéressant si vous l'essayez par vous-même."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p1rqV4bxn41b"
   },
   "source": [
    "Le premier exercice est de compléter la classe ManualAudioNet. J'ai défini tous les layers, mais vous devez implémenter la \"forward propagation\". J'ai donné un exemple avec la première couche de convolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9fiG3HKwYhV7"
   },
   "outputs": [],
   "source": [
    "class ManualAudioNet(nn.Module):\n",
    "    def __init__(self, n_classes=10, dropout_probability=0.2):\n",
    "        super().__init__()\n",
    "        self.n_classes = n_classes\n",
    "        self.dropout_probability = dropout_probability\n",
    "        # repeating layers\n",
    "        self.drop_layer =  nn.Dropout(self.dropout_probability)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        # conv layers\n",
    "        self.conv1 = nn.Conv1d(in_channels=1, out_channels=32, kernel_size=8, stride=4)\n",
    "        self.bn1 = nn.BatchNorm1d(32)\n",
    "        self.conv2 = nn.Conv1d(in_channels=32, out_channels=64, kernel_size=8, stride=4)\n",
    "        self.bn2 = nn.BatchNorm1d(64)\n",
    "        self.conv3 = nn.Conv1d(in_channels=64, out_channels=128, kernel_size=8,stride=4)\n",
    "        self.bn3 = nn.BatchNorm1d(128)\n",
    "        self.maxpool = nn.MaxPool1d(5)\n",
    "\n",
    "        # linear layers\n",
    "        self.lin1 = nn.Linear(128, 128)\n",
    "        self.lin2 = nn.Linear(128, self.n_classes)\n",
    "\n",
    "    def forward(self, input):\n",
    "        # first layer : conv1d + relu + dropout + batch_norm\n",
    "        out = self.bn1(self.drop_layer(self.relu(self.conv1(input))))\n",
    "        # second layer : conv1d + relu + dropout + batch_norm\n",
    "        out = self.bn2(self.drop_layer(self.relu(self.conv2(out))))\n",
    "        # third layer : conv1d + relu + dropout + batch_norm\n",
    "        out = self.bn3(self.drop_layer(self.relu(self.conv3(out))))\n",
    "        # fourth layer : maxpool + taking the mean over the last dimension\n",
    "        out = self.maxpool(out).mean(-1)\n",
    "\n",
    "        # fifth layer : linear + relu + dropout\n",
    "        out = self.drop_layer(self.relu(self.lin1(out)))\n",
    "        # sixth layer : linear + return the output\n",
    "        out = self.lin2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Je vous laisse maintenant tester si la sortie de votre réseau de neurone est correcte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "ipzr3thSoUDp"
   },
   "outputs": [],
   "source": [
    "test_model = ManualAudioNet()\n",
    "test_model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    out = test_model(torch.tensor(ds_train[1][\"audio\"].data()['value']).transpose(1,0).float().unsqueeze(0))\n",
    "assert out.shape == torch.Size([1, 10]), print(f\"La sortie est de taille {out.shape}, alors qu'elle devrait être de taille {torch.Size([1, 10])}\")\n",
    "print(\"Test réussi!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aar5d-4coNqg"
   },
   "source": [
    "Maintenant que le modèle est implémenté, on doit vérifier s'il est possible de trouver un GPU au lieu d'utiliser un CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EinUDYdfQStT"
   },
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q-Zbpo5UqTH6"
   },
   "source": [
    "On définit le modèle, la perte d'entraînement et notre optimiseur. J'ai décidé d'utiliser [Adam](https://pytorch.org/docs/stable/generated/torch.optim.Adam.html), car c'est un optimiseur bien connu, mais on aurait pu utiliser SGD ou autre.\n",
    "\n",
    "La perte que l'on utilise est la Cross Entropy Loss :\n",
    "\n",
    "$$\\ell(x,y) = -\\log \\frac{\\exp\\big(MLP(x)_{y}\\big)}{\\sum_{c=1}^C \\exp\\big(MLP(x)_{c}\\big)} $$\n",
    "\n",
    "Avec $C$ le nombre de classes et $MLP(x)_c$ la prédiction pour la $c$-ième classe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Pa02uAjWQWRS"
   },
   "outputs": [],
   "source": [
    "# on crée le modèle puis on le met sur le gpu\n",
    "model = ManualAudioNet(n_classes=10, dropout_probability=0.2).to(device)\n",
    "\n",
    "# set the loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# set the optimizer\n",
    "# Vous pouvez jouer avec le learning rate, j'ai trouvé que 0.005 fonctionnait plutôt bien\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TopGmOEbqbwc"
   },
   "source": [
    "Vous devez maintenant implémenter l'entraînement du modèle. Les instructions sont mises dans le code, vous devez simplement finir chaque ligne.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "hxSWvXHBDGNg"
   },
   "outputs": [],
   "source": [
    "for epoch in range(max_epochs):  # loop over the dataset multiple times    \n",
    "    running_loss = 0.0\n",
    "    with tqdm.tqdm(total=len(train_loader), desc=\"Epoch %s\" % str(epoch+1)) as pbar:\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\") \n",
    "            for batch in train_loader:\n",
    "        \n",
    "                inputs, targets = batch\n",
    "        \n",
    "                inputs = inputs.to(device)\n",
    "                targets = targets.to(device)\n",
    "        \n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "        \n",
    "                # forward + backward + optimize\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "        \n",
    "                # print statistics\n",
    "                running_loss += loss.item()\n",
    "                pbar.update(1)\n",
    "            pbar.set_postfix({'loss': f\"{running_loss/len(ds_train):.5f}\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GJCPVIHrRv5p"
   },
   "source": [
    "Finalement, on va tester le modèle sur les données d'entraînement. La majorité du code est pareil, mais cette fois ci on va calculer l'accuracy au lieu de la cross entropy.\n",
    "\n",
    "La formule de l'accuracy est la suivante :\n",
    "\n",
    "$$Acc = \\frac{1}{n}\\sum_{i=1}^n \\begin{cases} 1 & \\text{si } \\widehat{y}_i = y_i \\\\ 0 & \\text{si } \\widehat{y}_i \\neq y_i\\end{cases} $$\n",
    "\n",
    "pour un jeu de données $S = \\{(x_i, y_i)\\}_{i=1}^n$ et $\\widehat{y}_i$ la classe prédite par $MLP(x_i)$.\n",
    "\n",
    "\n",
    "Puisqu'on veut calculer l'accuracy sur le jeu de données et non sur chaque batch, calculez simplement le nombre de données bien prédites ($n \\cdot Acc$) et le code va automatiquement diviser par la taille du jeu de données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "TY4QUILATk3M"
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "model.to(device)\n",
    "\n",
    "acc = 0\n",
    "with torch.no_grad():\n",
    "    with tqdm.tqdm(total=len(test_loader), desc=\"Computing test error\") as pbar:\n",
    "        for sample in test_loader:\n",
    "        \n",
    "            inputs, targets = sample\n",
    "            \n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            pred = outputs.argmax(-1)\n",
    "            acc_batch = (targets == pred).sum().item()\n",
    "            acc += acc_batch\n",
    "            pbar.update(1)\n",
    "\n",
    "model.cpu()\n",
    "\n",
    "acc = acc / len(ds_test)\n",
    "print(f\"L'accuracy sur le jeu de données de test est de {100*acc:.2f} %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "editable": true,
    "id": "BO27F1slNCuj",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(20,5))\n",
    "\n",
    "acc, conf_mat = compute_accuracy_and_conf_mat(model, testing_train_loader, device)\n",
    "acc = acc / len(ds_train)\n",
    "sn.heatmap(conf_mat.to(int), annot=True, fmt=\"d\", ax=axs[0])\n",
    "axs[0].set_title(\"Matrice de confusion du jeu de donnés d'entraînement\")\n",
    "print(f\"L'accuracy sur le jeu de données d'entraînement est de {100*acc:.2f} %\")\n",
    "\n",
    "acc, conf_mat = compute_accuracy_and_conf_mat(model, validation_loader, device)\n",
    "acc = acc / len(ds_val)\n",
    "sn.heatmap(conf_mat.to(int), annot=True, fmt=\"d\", ax=axs[1])\n",
    "axs[1].set_title(\"Matrice de confusion du jeu de donnés de validation\")\n",
    "print(f\"L'accuracy sur le jeu de données de validation est de {100*acc:.2f} %\")\n",
    "\n",
    "acc, conf_mat = compute_accuracy_and_conf_mat(model, test_loader, device)\n",
    "acc = acc / len(ds_test)\n",
    "sn.heatmap(conf_mat.to(int), annot=True, fmt=\"d\", ax=axs[2])\n",
    "axs[2].set_title(\"Matrice de confusion du jeu de donnés de test\")\n",
    "print(f\"L'accuracy sur le jeu de données de test est de {100*acc:.2f} %\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
